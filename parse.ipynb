{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c320f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import NamedTuple, List\n",
    "\n",
    "class Action(NamedTuple):\n",
    "    date: date\n",
    "    action: str\n",
    "\n",
    "class Run(NamedTuple):\n",
    "    date: date\n",
    "    run: int\n",
    "    precursor: str\n",
    "    co_reactant: str\n",
    "    process: str\n",
    "    sequence: str\n",
    "    T: int\n",
    "    P: int\n",
    "\n",
    "ACTIONS: List[Action] = []\n",
    "RUNS: List[Run] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640bda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "from parse import parse, Result\n",
    "import string\n",
    "from typing import cast\n",
    "\n",
    "def parse_experiment_file(buffer: io.TextIOBase, filename: str):\n",
    "    global_date: date = datetime.strptime(filename, \"%Y%m%d.txt\")\n",
    "    \n",
    "    global_T: int\n",
    "    global_P: int\n",
    "\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Register Globals\n",
    "    _result = find_read_line(buffer, \"T{:s}={:s}{T:g}{T_unit:l}\")\n",
    "    global_T = _result[\"T\"]\n",
    "    \n",
    "    _result = find_read_line(buffer, \"P{:s}={:s}{P:g}{:s}{P_unit:l}\")\n",
    "    global_P = _result[\"P\"]\n",
    "\n",
    "    # Action: Crystal\n",
    "    if not find_read_separator(buffer, \"_\", 28):\n",
    "        raise ValueError(\"Could not find crystal section\")\n",
    "    action_label = read_nonws_line(buffer)\n",
    "    \n",
    "    _result = find_read_line(buffer, \"{action_type} {month:d}/{day:d}/{year:d}\")\n",
    "    action_type = _result[\"action_type\"]\n",
    "    action_date: date = datetime(\n",
    "        year=_result[\"year\"],\n",
    "        month=_result[\"month\"],\n",
    "        day=_result[\"day\"]\n",
    "    )\n",
    "\n",
    "    # Action: Wafer\n",
    "    if not find_read_separator(buffer, \"_\", 28):\n",
    "        raise ValueError(\"Could not find wafer section\")\n",
    "    wafer_label = read_nonws_line(buffer)\n",
    "    # discard wafer label for now\n",
    "    \n",
    "    # Register Action\n",
    "    this_action = Action(\n",
    "        date=action_date,\n",
    "        action=f\"{action_label} {action_type}\"\n",
    "    )\n",
    "    ACTIONS.append(this_action)\n",
    "\n",
    "    # Runs\n",
    "    while True:\n",
    "        _separator = find_read_separator(buffer, \"_\", 28)\n",
    "        if not _separator:\n",
    "            break \n",
    "\n",
    "        _result = find_read_line(buffer, \"Run{:s}{number:d}\")\n",
    "        if not \"number\" in _result:\n",
    "            break\n",
    "        \n",
    "        run_number = _result[\"number\"]\n",
    "\n",
    "        _result = find_read_line(buffer, \"{cycles_str}{:s}{precursor}|{co_reactant}\")\n",
    "        run_cycles_str = _result[\"cycles_str\"]\n",
    "        run_precursor = _result[\"precursor\"]\n",
    "        run_co_reactant = _result[\"co_reactant\"]\n",
    "\n",
    "        run_process = read_nonws_line(buffer)\n",
    "        if not run_process:\n",
    "            raise ValueError(f\"Missing run process\")\n",
    "        _run_proc_partitions = run_process.count(\"|\") \n",
    "\n",
    "        run_sequence = read_nonws_line(buffer)\n",
    "        if not run_sequence:\n",
    "            raise ValueError(f\"Missing run sequence\")\n",
    "        _run_seq_partitions = run_sequence.count(\"|\")\n",
    "        \n",
    "        if (_run_proc_partitions != _run_seq_partitions):\n",
    "            raise ValueError(f\"Mismatch in partitions between process and run sequence in run #{run_number}\")\n",
    "        \n",
    "        # Register Run\n",
    "        this_run = Run(\n",
    "            date=global_date,\n",
    "            run=run_number,\n",
    "            precursor=run_precursor,\n",
    "            co_reactant=run_co_reactant,\n",
    "            process=f\"{run_cycles_str} cycles {run_process}\",\n",
    "            sequence=run_sequence,\n",
    "            T=global_T,\n",
    "            P=global_P\n",
    "        )\n",
    "        RUNS.append(this_run)\n",
    "\n",
    "def read_nonws_line(buffer: io.TextIOBase) -> str | None: \n",
    "    while True:\n",
    "        line = buffer.readline()\n",
    "        if not line:\n",
    "            return None\n",
    "\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        return line\n",
    "\n",
    "def find_read_line(buffer: io.TextIOBase, pattern: str) -> dict:\n",
    "    formatter = string.Formatter()\n",
    "    field_names = [fname for _, fname, _, _ in formatter.parse(pattern) if fname]\n",
    "\n",
    "    while True:\n",
    "        line = read_nonws_line(buffer)\n",
    "        if not line:\n",
    "            print(f\"Could not find line: {pattern}\")\n",
    "            return {}\n",
    "\n",
    "        result = parse(pattern, line.strip())\n",
    "        if not result:\n",
    "            continue\n",
    "        else:\n",
    "            result = cast(Result, result) \n",
    "\n",
    "        # Check that all named fields are non-empty\n",
    "        if all(result.named.get(name) not in [None, \"\"] for name in field_names):\n",
    "            return result.named\n",
    "        \n",
    "def find_read_separator(buffer: io.TextIOBase, tile: str, threshold: int):\n",
    "    while True:\n",
    "        line = read_nonws_line(buffer)\n",
    "        if not line:\n",
    "            return None\n",
    "        \n",
    "        if not line.startswith(tile * threshold):\n",
    "            continue\n",
    "        \n",
    "        return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae6b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_experiment(path):\n",
    "    f = open(path, 'r')\n",
    "    parse_experiment_file(f, os.path.basename(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea21803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import pandas as pd\n",
    "\n",
    "def update_experiment_df(df: pd.DataFrame):\n",
    "    for action in ACTIONS:\n",
    "        action_row = pd.DataFrame([{\n",
    "            'Date': int(action.date.strftime(\"%Y%m%d\")),\n",
    "            'Run/Action': action.action,\n",
    "            'Precursor': None,\n",
    "            'Co-reactant': None,\n",
    "            'Co-absorbate': None,\n",
    "            '# Cycles': None,\n",
    "            'Process': None,\n",
    "            'Sequence': None,\n",
    "            'Furnace T (°C)': None,\n",
    "            'P (Torr)': None,\n",
    "        }])\n",
    "\n",
    "        df = pd.concat([df, action_row], ignore_index=True)\n",
    "\n",
    "    for run in RUNS:\n",
    "        run_row = pd.DataFrame([{\n",
    "            'Date': int(run.date.strftime(\"%Y%m%d\")),\n",
    "            'Run/Action': run.run,\n",
    "            'Precursor': run.precursor,\n",
    "            'Co-reactant': run.co_reactant,\n",
    "            'Co-absorbate': None,\n",
    "            '# Cycles': None,\n",
    "            'Process': run.process,\n",
    "            'Sequence': run.sequence,\n",
    "            'Furnace T (°C)': run.T,\n",
    "            'P (Torr)': run.P,\n",
    "        }])\n",
    "\n",
    "        df = pd.concat([df, run_row], ignore_index=True)\n",
    "\n",
    "    df = df.sort_values(by=['Date', 'Run/Action'], ascending=[True, True])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9123d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find line: Run{:s}{number:d}\n",
      "[Run(date=datetime.datetime(2024, 1, 23, 0, 0), run=1, precursor='cycles TMA', co_reactant='H2O', process='10 cycles TMA|Purge|H2O|purge\\n', sequence='2|28|0.5|59.5\\n', T=285.0, P=1.0), Run(date=datetime.datetime(2024, 1, 23, 0, 0), run=2, precursor='cycles TMA', co_reactant='tbuoh', process='10 cycles TMA|Purge|tbuoh|purge\\n', sequence='2|28|0.5|59.5\\n', T=285.0, P=1.0), Run(date=datetime.datetime(2024, 1, 24, 0, 0), run=1, precursor='cycles TMA', co_reactant='TbuOH', process='30 cycles TMA|Purge|tbuoh|purge\\n', sequence='2|28|0.5|179.5\\n', T=120.0, P=1.0), Run(date=datetime.datetime(2024, 1, 25, 0, 0), run=1, precursor='cycles TMA', co_reactant='TbuOH', process='15 cycles TMA|Purge|tbuoh|purge\\n', sequence='2|28|0.5|179.5\\n', T=285.0, P=1.0), Run(date=datetime.datetime(2024, 1, 25, 0, 0), run=2, precursor='cycles TMA', co_reactant='h2o', process='15 cycles TMA|Purge|h2o|purge\\n', sequence='2|28|0.5|179.5\\n', T=285.0, P=1.0)]\n",
      "[Action(date=datetime.datetime(2024, 1, 22, 0, 0), action='NEW Au 285C crystal \\n loaded'), Action(date=datetime.datetime(2024, 1, 23, 0, 0), action='NEW Au 120C crystal \\n loaded'), Action(date=datetime.datetime(2024, 1, 24, 0, 0), action='NEW Au 285C crystal \\n loaded')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fiery\\AppData\\Local\\Temp\\ipykernel_26832\\2196050099.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, run_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "parse_experiment('data/20240123.txt')\n",
    "parse_experiment('data/20240124.txt')\n",
    "parse_experiment('data/20240125.txt')\n",
    "print(RUNS)\n",
    "print(ACTIONS)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = update_experiment_df(df)\n",
    "df.to_excel('output.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lynden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
